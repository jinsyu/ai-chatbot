"""
Text-to-SQL Agent using LangGraph
ìì—°ì–´ ì¿¼ë¦¬ë¥¼ SQLë¡œ ë³€í™˜í•˜ê³  ì‹¤í–‰í•˜ëŠ” ì „ìš© ì—ì´ì „íŠ¸
"""

from typing import List, TypedDict, Annotated, Dict, Any, Optional
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_openai import AzureChatOpenAI
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from sqlalchemy import create_engine, text, inspect
import os
import re
from dotenv import load_dotenv
from datetime import datetime
import json
from decimal import Decimal
import traceback

load_dotenv()

# ========================
# Configuration
# ========================

# Decimalì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” JSON Encoder
class DecimalEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, Decimal):
            return float(obj)
        return super(DecimalEncoder, self).default(obj)

# Azure OpenAI ì„¤ì •
def get_llm(temperature=0.0):
    """Azure OpenAI LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return AzureChatOpenAI(
        deployment_name=os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME", "gpt-4o"),
        api_key=os.getenv("AZURE_OPENAI_API_KEY"),
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
        api_version=os.getenv("AZURE_OPENAI_API_VERSION", "2024-08-01-preview"),
        temperature=temperature,
        # max_tokens=2000
    )

# ========================
# State Definition
# ========================

class TextToSqlState(TypedDict):
    """Text-to-SQL ì—ì´ì „íŠ¸ì˜ ìƒíƒœ"""
    messages: Annotated[List[BaseMessage], add_messages]
    user_query: str
    conversation_history: Optional[List[Dict]]
    schema_info: Optional[str]
    generated_sql: Optional[str]
    validation_result: Optional[Dict]
    query_results: Optional[List[Dict]]
    formatted_response: Optional[str]
    error: Optional[str]
    retry_count: int

# ========================
# Text-to-SQL Node
# ========================

class TextToSqlNode:
    """
    ğŸ—„ï¸ Text-to-SQL ë…¸ë“œ
    ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆì˜ë¥¼ SQLë¡œ ë³€í™˜í•˜ê³  ì‹¤í–‰í•˜ëŠ” í•µì‹¬ ë…¸ë“œ
    """
    
    def __init__(self, db_url: str):
        self.db_url = db_url
        # ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ì„¤ì •
        self.engine = create_engine(
            db_url,
            pool_size=20,  # ì»¤ë„¥ì…˜ í’€ í¬ê¸° ì¦ê°€
            max_overflow=40,  # ìµœëŒ€ ì˜¤ë²„í”Œë¡œìš° ì¦ê°€
            pool_timeout=1200,  # íƒ€ì„ì•„ì›ƒ 20ë¶„ìœ¼ë¡œ ì¦ê°€
            pool_recycle=3600  # 1ì‹œê°„ë§ˆë‹¤ ì»¤ë„¥ì…˜ ì¬í™œìš©
        )
        self.llm = get_llm()
        self.max_retries = 3
        self.max_rows = 100000  # ìµœëŒ€ 10,000í–‰ ë°˜í™˜
        self.default_limit = 500000  # ê¸°ë³¸ LIMIT 50ë§Œê±´
    
    def get_detailed_schema(self) -> str:
        """ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ìƒì„¸íˆ ì¶”ì¶œ"""
        inspector = inspect(self.engine)
        schema_info = []
        
        for table_name in inspector.get_table_names():
            schema_info.append(f"\nTable: {table_name}")
            
            # ì»¬ëŸ¼ ì •ë³´
            columns = inspector.get_columns(table_name)
            for col in columns:
                col_type = str(col['type'])
                nullable = " (nullable)" if col['nullable'] else " (NOT NULL)"
                default = f" DEFAULT {col['default']}" if col.get('default') else ""
                schema_info.append(f"  - {col['name']}: {col_type}{nullable}{default}")
            
            # Primary Key
            pk = inspector.get_pk_constraint(table_name)
            if pk and pk['constrained_columns']:
                schema_info.append(f"  Primary Key: {', '.join(pk['constrained_columns'])}")
            
            # Foreign Keys
            fks = inspector.get_foreign_keys(table_name)
            for fk in fks:
                schema_info.append(f"  Foreign Key: {', '.join(fk['constrained_columns'])} -> {fk['referred_table']}.{', '.join(fk['referred_columns'])}")
            
            # Indexes
            indexes = inspector.get_indexes(table_name)
            for idx in indexes:
                if not idx.get('unique'):
                    schema_info.append(f"  Index: {idx['name']} on ({', '.join(idx['column_names'])})")
        
        return "\n".join(schema_info)
    
    async def analyze_schema(self, state: TextToSqlState) -> Dict:
        """ìŠ¤í‚¤ë§ˆ ë¶„ì„ ë‹¨ê³„"""
        print("\nğŸ“Š Analyzing database schema...")
        
        try:
            schema_info = self.get_detailed_schema()
            
            # ìŠ¤í‚¤ë§ˆ ìš”ì•½ ìƒì„±
            table_count = schema_info.count('\nTable:')
            
            return {
                "schema_info": schema_info,
                "messages": [AIMessage(content=f"Schema analyzed: {table_count} tables found")]
            }
        except Exception as e:
            error_msg = f"Schema analysis failed: {str(e)}"
            print(f"âŒ {error_msg}")
            return {
                "error": error_msg,
                "messages": [AIMessage(content=error_msg)]
            }
    
    async def generate_sql(self, state: TextToSqlState) -> Dict:
        """SQL ìƒì„± ë‹¨ê³„"""
        print("\nğŸ”§ Generating SQL query...")
        
        if not state.get('schema_info'):
            return {
                "error": "No schema information available",
                "messages": [AIMessage(content="Schema information is required")]
            }
        
        # í–¥ìƒëœ í”„ë¡¬í”„íŠ¸
        prompt = f"""You are an expert PostgreSQL query generator. Convert the natural language query to SQL.

DATABASE SCHEMA:
{state['schema_info']}

STRICT RULES:
1. Generate ONLY SELECT queries (read-only operations)
2. Use double quotes for case-sensitive column names (e.g., "userId", "createdAt")
3. Use single quotes for string values
4. Always use explicit JOIN syntax, never implicit joins
5. Add appropriate WHERE clauses for filtering
6. Include ORDER BY for sorted results
7. Add LIMIT clause to prevent large result sets (default: LIMIT 100)
8. Use aggregate functions (COUNT, SUM, AVG, etc.) when appropriate
9. Handle NULL values properly with IS NULL/IS NOT NULL
10. Use DISTINCT when uniqueness is required
11. IMPORTANT: price_per_kg column contains text ranges like "10~50", NOT numeric values - DO NOT cast to NUMERIC

COMMON PATTERNS:
- Date filtering: Use DATE_TRUNC() or date comparison operators
- Text search: Use ILIKE for case-insensitive matching
- Counting: Use COUNT(*) for row counts, COUNT(DISTINCT column) for unique counts
- Grouping: Always include non-aggregate columns in GROUP BY
- Price columns: Usually stored as TEXT with ranges (e.g., "10~50"), not numeric values

IMPORTANT SCHEMA NOTES:
- If you see columns like 'price', 'price_per_kg', etc., they are likely TEXT fields with ranges
- For aggregations on price fields, use COUNT instead of SUM
- For sales/revenue calculations, look for actual numeric columns, not price range fields

USER QUERY: {state['user_query']}

Generate a single PostgreSQL query. Return ONLY the SQL query without any explanation or markdown:
"""
        
        try:
            response = await self.llm.ainvoke([SystemMessage(content=prompt)])
            sql_query = response.content.strip()
            
            # SQL ì •ë¦¬
            sql_query = re.sub(r'```sql\s*', '', sql_query)
            sql_query = re.sub(r'```\s*', '', sql_query)
            sql_query = sql_query.strip()
            
            # ì„¸ë¯¸ì½œë¡  í™•ì¸
            if not sql_query.endswith(';'):
                sql_query += ';'
            
            print(f"Generated SQL: {sql_query}")
            
            return {
                "generated_sql": sql_query,
                "messages": [AIMessage(content=f"SQL generated successfully")]
            }
            
        except Exception as e:
            error_msg = f"SQL generation failed: {str(e)}"
            print(f"âŒ {error_msg}")
            return {
                "error": error_msg,
                "messages": [AIMessage(content=error_msg)]
            }
    
    async def validate_sql(self, state: TextToSqlState) -> Dict:
        """SQL ê²€ì¦ ë‹¨ê³„"""
        print("\nâœ… Validating SQL query...")
        
        sql = state.get('generated_sql', '')
        
        if not sql:
            return {
                "validation_result": {"valid": False, "reason": "No SQL query to validate"},
                "messages": [AIMessage(content="No SQL query to validate")]
            }
        
        # ë³´ì•ˆ ê²€ì¦
        forbidden_keywords = [
            'INSERT', 'UPDATE', 'DELETE', 'DROP', 'CREATE', 'ALTER', 
            'TRUNCATE', 'GRANT', 'REVOKE', 'EXECUTE', 'EXEC'
        ]
        
        sql_upper = sql.upper()
        
        for keyword in forbidden_keywords:
            if re.search(r'\b' + keyword + r'\b', sql_upper):
                return {
                    "validation_result": {"valid": False, "reason": f"Forbidden operation: {keyword}"},
                    "error": f"Security violation: {keyword} operations not allowed",
                    "messages": [AIMessage(content=f"Forbidden operation detected: {keyword}")]
                }
        
        # SELECT ë˜ëŠ” WITHë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸
        if not (sql_upper.startswith('SELECT') or sql_upper.startswith('WITH')):
            return {
                "validation_result": {"valid": False, "reason": "Must be SELECT query"},
                "error": "Only SELECT queries are allowed",
                "messages": [AIMessage(content="Query must start with SELECT or WITH")]
            }
        
        # SQL Injection íŒ¨í„´ ì²´í¬
        dangerous_patterns = [
            r';\s*DROP',
            r';\s*DELETE',
            r'--\s*',
            r'/\*.*\*/',
            r'UNION\s+ALL\s+SELECT.*FROM\s+information_schema'
        ]
        
        for pattern in dangerous_patterns:
            if re.search(pattern, sql, re.IGNORECASE):
                return {
                    "validation_result": {"valid": False, "reason": "Dangerous pattern detected"},
                    "error": "Potentially dangerous SQL pattern detected",
                    "messages": [AIMessage(content="Security risk detected in query")]
                }
        
        # LIMIT ì²´í¬ ë° ì¶”ê°€ (ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬)
        if 'LIMIT' not in sql_upper:
            sql = sql.replace(';', f' LIMIT {self.default_limit};')
            state['generated_sql'] = sql
            print(f"Added LIMIT {self.default_limit} to query")
        
        return {
            "validation_result": {"valid": True, "sql": sql},
            "generated_sql": sql,
            "messages": [AIMessage(content="SQL validation passed")]
        }
    
    async def execute_query(self, state: TextToSqlState) -> Dict:
        """ì¿¼ë¦¬ ì‹¤í–‰ ë‹¨ê³„"""
        print("\nğŸš€ Executing SQL query...")
        
        validation = state.get('validation_result', {})
        if not validation.get('valid'):
            return {
                "error": "Cannot execute invalid query",
                "messages": [AIMessage(content="Query validation failed")]
            }
        
        sql = state.get('generated_sql', '')
        
        try:
            with self.engine.connect() as conn:
                result = conn.execute(text(sql))
                rows = result.fetchall()
                
                # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬)
                if rows:
                    columns = result.keys()
                    results = []
                    # ìµœëŒ€ max_rowsê¹Œì§€ ì²˜ë¦¬
                    for row in rows[:self.max_rows]:
                        row_dict = {}
                        for i, col in enumerate(columns):
                            value = row[i]
                            # Decimal, datetime ë“± ì²˜ë¦¬
                            if isinstance(value, Decimal):
                                value = float(value)
                            elif isinstance(value, datetime):
                                value = value.isoformat()
                            row_dict[col] = value
                        results.append(row_dict)
                    
                    # ì „ì²´ í–‰ ìˆ˜ ì •ë³´ ì¶”ê°€
                    total_rows = len(rows)
                    if total_rows > self.max_rows:
                        print(f"âš ï¸ Results truncated: showing {self.max_rows} of {total_rows} rows")
                else:
                    results = []
                
                print(f"âœ… Query executed: {len(results)} rows returned")
                
                return {
                    "query_results": results,
                    "messages": [AIMessage(content=f"Query executed: {len(results)} rows returned")]
                }
                
        except Exception as e:
            error_msg = f"Query execution failed: {str(e)}"
            print(f"âŒ {error_msg}")
            traceback.print_exc()
            
            return {
                "error": error_msg,
                "messages": [AIMessage(content=error_msg)]
            }
    
    async def format_response(self, state: TextToSqlState) -> Dict:
        """ì‘ë‹µ í¬ë§·íŒ… ë‹¨ê³„"""
        print("\nğŸ“ Formatting response...")
        
        results = state.get('query_results', [])
        sql = state.get('generated_sql', '')
        query = state.get('user_query', '')
        
        if state.get('error'):
            response = f"âŒ Error: {state['error']}"
        elif not results:
            response = "No results found for your query."
        else:
            # ê²°ê³¼ ìš”ì•½
            response_parts = []
            response_parts.append(f"âœ… Query executed successfully")
            response_parts.append(f"ğŸ“Š Found {len(results)} results\n")
            
            # SQL ì¿¼ë¦¬ í‘œì‹œ
            response_parts.append("**Generated SQL:**")
            response_parts.append(f"```sql\n{sql}\n```\n")
            
            # ê²°ê³¼ í…Œì´ë¸” (ì²˜ìŒ 20ê°œë§Œ)
            if results:
                response_parts.append("**Results:**")
                
                # Markdown í…Œì´ë¸” ìƒì„±
                headers = list(results[0].keys())
                table = "| " + " | ".join(headers) + " |\n"
                table += "| " + " | ".join(["---"] * len(headers)) + " |\n"
                
                for row in results[:20]:
                    values = []
                    for h in headers:
                        val = row.get(h, '')
                        if val is None:
                            val = 'NULL'
                        elif isinstance(val, str) and len(val) > 50:
                            val = val[:47] + '...'
                        values.append(str(val))
                    table += "| " + " | ".join(values) + " |\n"
                
                response_parts.append(table)
                
                if len(results) > 20:
                    response_parts.append(f"\n*... and {len(results) - 20} more rows*")
            
            response = "\n".join(response_parts)
        
        return {
            "formatted_response": response,
            "messages": [AIMessage(content="Response formatted")]
        }

# ========================
# Main Agent
# ========================

class TextToSqlAgent:
    """Text-to-SQL ì—ì´ì „íŠ¸"""
    
    def __init__(self, db_url: str):
        self.db_url = db_url
        self.node = TextToSqlNode(db_url)
        self.graph = self._build_graph()
    
    def _build_graph(self) -> StateGraph:
        """LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""
        workflow = StateGraph(TextToSqlState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("analyze_schema", self.node.analyze_schema)
        workflow.add_node("generate_sql", self.node.generate_sql)
        workflow.add_node("validate_sql", self.node.validate_sql)
        workflow.add_node("execute_query", self.node.execute_query)
        workflow.add_node("format_response", self.node.format_response)
        
        # ì—£ì§€ ì„¤ì •
        workflow.set_entry_point("analyze_schema")
        
        # ì„ í˜• í”Œë¡œìš°
        workflow.add_edge("analyze_schema", "generate_sql")
        workflow.add_edge("generate_sql", "validate_sql")
        
        # ì¡°ê±´ë¶€ ì—£ì§€: ê²€ì¦ ê²°ê³¼ì— ë”°ë¼
        workflow.add_conditional_edges(
            "validate_sql",
            lambda x: "execute" if x.get('validation_result', {}).get('valid') else "retry",
            {
                "execute": "execute_query",
                "retry": END  # ì¬ì‹œë„ ë¡œì§ì€ ì™¸ë¶€ì—ì„œ ì²˜ë¦¬
            }
        )
        
        workflow.add_edge("execute_query", "format_response")
        workflow.add_edge("format_response", END)
        
        return workflow.compile()
    
    async def run(self, query: str, conversation_history: List[Dict] = None) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ ì‹¤í–‰"""
        print(f"\n{'='*60}")
        print(f"ğŸ¤– Text-to-SQL Agent Started")
        print(f"ğŸ“ Query: {query}")
        print(f"{'='*60}")
        
        initial_state = {
            "messages": [HumanMessage(content=query)],
            "user_query": query,
            "conversation_history": conversation_history or [],
            "schema_info": None,
            "generated_sql": None,
            "validation_result": None,
            "query_results": None,
            "formatted_response": None,
            "error": None,
            "retry_count": 0
        }
        
        try:
            result = await self.graph.ainvoke(initial_state)
            
            print(f"\n{'='*60}")
            print(f"âœ… Agent Completed Successfully")
            print(f"{'='*60}\n")
            
            return {
                "success": True,
                "query": query,
                "sql": result.get("generated_sql"),
                "response": result.get("formatted_response"),
                "results": result.get("query_results"),
                "error": result.get("error")
            }
            
        except Exception as e:
            print(f"\nâŒ Agent failed: {str(e)}")
            traceback.print_exc()
            
            return {
                "success": False,
                "query": query,
                "error": str(e),
                "response": f"An error occurred: {str(e)}"
            }

# ========================
# Test & Main
# ========================

async def test_agent():
    """ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸"""
    
    # í…ŒìŠ¤íŠ¸ìš© ì¿¼ë¦¬ë“¤
    test_queries = [
        "Show me all users",
        "How many chats are there?",
        "Show recent messages with user information",
        "What are the most active users?",
    ]
    
    # DB URL from environment
    db_url = os.getenv("DATABASE_URL")
    if not db_url:
        print("âŒ DATABASE_URL not set in environment")
        return
    
    agent = TextToSqlAgent(db_url)
    
    for query in test_queries:
        print(f"\n{'='*80}")
        print(f"Testing: {query}")
        print('='*80)
        
        result = await agent.run(query)
        
        if result['success']:
            print(f"\nâœ… Success!")
            print(f"SQL: {result.get('sql', 'N/A')}")
            print(f"Results: {len(result.get('results', [])) if result.get('results') else 0} rows")
        else:
            print(f"\nâŒ Failed: {result.get('error')}")

if __name__ == "__main__":
    import asyncio
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(test_agent())