#!/usr/bin/env python3
"""
ZMMR0001 ìì¬ë¦¬ìŠ¤íŠ¸ Excel Import
Excel íŒŒì¼ì„ SQLite ë°ì´í„°ë² ì´ìŠ¤ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
"""

import os
import pandas as pd
import numpy as np
from sqlalchemy import create_engine, text
from datetime import datetime
import logging
from typing import Dict, List, Any

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MaterialsDataImporter:
    def __init__(self, excel_path: str, db_path: str = "db.sqlite"):
        self.excel_path = excel_path
        self.db_path = db_path
        self.engine = None
        self.table_name = 'sap_zmmr0001_materials'
        self.df = None
        
    def connect_database(self):
        """SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        try:
            # SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
            self.engine = create_engine(f'sqlite:///{self.db_path}')
            logger.info(f"âœ… SQLite ì—°ê²° ì„±ê³µ: {self.db_path}")
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            with self.engine.connect() as conn:
                result = conn.execute(text("SELECT sqlite_version()")).scalar()
                logger.info(f"  SQLite ë²„ì „: {result}")
            
            return True
        except Exception as e:
            logger.error(f"âŒ SQLite ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    def analyze_excel(self):
        """Excel íŒŒì¼ êµ¬ì¡° ë¶„ì„"""
        try:
            logger.info(f"ğŸ“Š Excel íŒŒì¼ ë¶„ì„ ì¤‘: {self.excel_path}")
            
            # Excel íŒŒì¼ì˜ ëª¨ë“  ì‹œíŠ¸ í™•ì¸
            xl_file = pd.ExcelFile(self.excel_path)
            logger.info(f"ì‹œíŠ¸ ëª©ë¡: {xl_file.sheet_names}")
            
            # ì²« ë²ˆì§¸ ì‹œíŠ¸ ì½ê¸° (ì²˜ìŒ ëª‡ í–‰ë§Œ ë¨¼ì € í™•ì¸)
            df_sample = pd.read_excel(self.excel_path, sheet_name=0, nrows=5)
            logger.info(f"\nğŸ“‹ ìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 5í–‰):")
            logger.info(df_sample.to_string())
            
            # ì „ì²´ ë°ì´í„° ì½ê¸°
            self.df = pd.read_excel(self.excel_path, sheet_name=0)
            
            # ë§ˆì§€ë§‰ í–‰ì´ í•©ê³„ í–‰ì¸ì§€ í™•ì¸
            last_row = self.df.iloc[-1]
            # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ìì¬ëª…ì— 'í•©ê³„'ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            if pd.isna(last_row.iloc[0]) or (isinstance(last_row.iloc[1], str) and 'í•©ê³„' in str(last_row.iloc[1]).lower()):
                logger.info("  âš ï¸ ë§ˆì§€ë§‰ í–‰ì´ í•©ê³„ í–‰ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì œì™¸í•©ë‹ˆë‹¤.")
                self.df = self.df[:-1]  # ë§ˆì§€ë§‰ í–‰ ì œì™¸
            
            logger.info(f"\nâœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            logger.info(f"  - í–‰ ìˆ˜: {len(self.df)}")
            logger.info(f"  - ì—´ ìˆ˜: {len(self.df.columns)}")
            
            # ì»¬ëŸ¼ ì •ë³´ ì¶œë ¥
            logger.info(f"\nğŸ“‹ ì»¬ëŸ¼ ì •ë³´:")
            for col in self.df.columns:
                dtype = str(self.df[col].dtype)
                null_count = self.df[col].isnull().sum()
                unique_count = self.df[col].nunique()
                
                # ìƒ˜í”Œ ê°’ (ì²˜ìŒ non-null ê°’)
                sample_val = None
                for val in self.df[col]:
                    if pd.notna(val):
                        sample_val = val
                        break
                
                logger.info(f"  - {col}: {dtype}")
                logger.info(f"    null: {null_count}, unique: {unique_count}, sample: {sample_val}")
            
            return True
            
        except Exception as e:
            logger.error(f"Excel íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def clean_and_prepare_data(self):
        """ë°ì´í„° ì •ë¦¬ ë° ì¤€ë¹„"""
        try:
            logger.info("ğŸ§¹ ë°ì´í„° ì •ë¦¬ ì¤‘...")
            
            # ì»¬ëŸ¼ëª… ì •ë¦¬ (ê³µë°± ì œê±°)
            self.df.columns = [col.strip() for col in self.df.columns]
            
            # ë°ì´í„° íƒ€ì… ì¶”ë¡  ë° ë³€í™˜
            for col in self.df.columns:
                # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
                if 'ì¼' in col or 'ë‚ ì§œ' in col or 'date' in col.lower():
                    try:
                        # ë‚ ì§œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (SQLiteëŠ” DATE íƒ€ì…ì´ ì—†ìŒ)
                        self.df[col] = pd.to_datetime(self.df[col], errors='coerce').dt.strftime('%Y-%m-%d')
                        logger.info(f"  {col}: ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜")
                    except:
                        pass
                
                # ìˆ«ìë¡œ ë³´ì´ëŠ” í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì²˜ë¦¬
                elif self.df[col].dtype == 'object':
                    # ìƒ˜í”Œ ê°’ í™•ì¸
                    sample = self.df[col].dropna().head()
                    if len(sample) > 0:
                        # ìˆ«ìë¡œ ë³€í™˜ ê°€ëŠ¥í•œì§€ í™•ì¸
                        try:
                            # ì½¤ë§ˆ ì œê±° í›„ ìˆ«ì ë³€í™˜ ì‹œë„
                            temp = self.df[col].astype(str).str.replace(',', '').str.replace(' ', '')
                            if temp.str.match(r'^-?\d+\.?\d*$').any():
                                # ì¼ë¶€ë¼ë„ ìˆ«ìë©´ ìˆ«ìë¡œ ë³€í™˜ ì‹œë„
                                self.df[col] = pd.to_numeric(temp, errors='coerce')
                                logger.info(f"  {col}: ìˆ«ì í˜•ì‹ìœ¼ë¡œ ë³€í™˜")
                        except:
                            pass
            
            # NaNì„ Noneìœ¼ë¡œ ë³€í™˜ (SQLite NULL)
            self.df = self.df.replace({np.nan: None})
            
            logger.info("âœ… ë°ì´í„° ì •ë¦¬ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return False
    
    def create_table(self):
        """SQLite í…Œì´ë¸” ìƒì„±"""
        try:
            logger.info(f"ğŸ“ {self.table_name} í…Œì´ë¸” ìƒì„± ì¤‘...")
            
            # ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ
            with self.engine.connect() as conn:
                conn.execute(text(f"DROP TABLE IF EXISTS {self.table_name}"))
                conn.commit()
            
            # pandas to_sqlì„ ì‚¬ìš©í•˜ì—¬ í…Œì´ë¸” ìë™ ìƒì„± (SQLiteëŠ” ë™ì  íƒ€ì…)
            # ì²« ë²ˆì§¸ í–‰ë§Œ ì‚¬ìš©í•˜ì—¬ ìŠ¤í‚¤ë§ˆ ìƒì„±
            self.df.head(1).to_sql(
                self.table_name,
                self.engine,
                if_exists='replace',
                index=False
            )
            
            # í…Œì´ë¸” ë¹„ìš°ê¸° (ìŠ¤í‚¤ë§ˆë§Œ ë‚¨ê¸°ê¸°)
            with self.engine.connect() as conn:
                conn.execute(text(f"DELETE FROM {self.table_name}"))
                conn.commit()
                
                # ì¸ë±ìŠ¤ ìƒì„± (ì£¼ìš” ì»¬ëŸ¼ì— ëŒ€í•´)
                try:
                    # ì»¬ëŸ¼ëª…ì— ë”°ë¼ ì¸ë±ìŠ¤ ìƒì„±
                    for col in self.df.columns:
                        if 'ìì¬' in col and ('ë²ˆí˜¸' in col or 'ì½”ë“œ' in col):
                            conn.execute(text(f"CREATE INDEX idx_{self.table_name}_material ON {self.table_name} (`{col}`)"))
                            logger.info(f"  ì¸ë±ìŠ¤ ìƒì„±: ìì¬ë²ˆí˜¸/ì½”ë“œ")
                        elif 'í”ŒëœíŠ¸' in col:
                            conn.execute(text(f"CREATE INDEX idx_{self.table_name}_plant ON {self.table_name} (`{col}`)"))
                            logger.info(f"  ì¸ë±ìŠ¤ ìƒì„±: í”ŒëœíŠ¸")
                        elif 'ìì¬ê·¸ë£¹' in col and '1' in col:  # ìì¬ê·¸ë£¹1 ê°™ì€ ê²½ìš°
                            conn.execute(text(f"CREATE INDEX idx_{self.table_name}_group ON {self.table_name} (`{col}`)"))
                            logger.info(f"  ì¸ë±ìŠ¤ ìƒì„±: ìì¬ê·¸ë£¹")
                    conn.commit()
                except Exception as e:
                    logger.warning(f"ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            
            logger.info(f"âœ… í…Œì´ë¸” ìƒì„± ì™„ë£Œ: {self.table_name}")
            return True
            
        except Exception as e:
            logger.error(f"í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def save_to_database(self):
        """ë°ì´í„°ë¥¼ SQLiteì— ì €ì¥"""
        try:
            logger.info(f"ğŸ’¾ {len(self.df)}ê°œ ë ˆì½”ë“œ ì €ì¥ ì¤‘...")
            
            # SQLiteëŠ” ë³€ìˆ˜ ì œí•œì´ ìˆìœ¼ë¯€ë¡œ ì‘ì€ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì €ì¥
            # ì»¬ëŸ¼ ìˆ˜ì— ë”°ë¼ ì²­í¬ í¬ê¸° ê²°ì •
            col_count = len(self.df.columns)
            max_vars = 900  # SQLite ì œí•œë³´ë‹¤ ì‘ê²Œ ì„¤ì • (ì•ˆì „ ë§ˆì§„)
            chunk_size = max_vars // col_count
            chunk_size = max(1, min(chunk_size, 100))  # 1-100 ì‚¬ì´ë¡œ ì œí•œ
            
            logger.info(f"  ì²­í¬ í¬ê¸°: {chunk_size} (ì»¬ëŸ¼ ìˆ˜: {col_count})")
            
            total_saved = 0
            
            for i in range(0, len(self.df), chunk_size):
                chunk = self.df.iloc[i:i+chunk_size]
                
                chunk.to_sql(
                    self.table_name,
                    self.engine,
                    if_exists='append',
                    index=False,
                    method='multi'
                )
                
                total_saved += len(chunk)
                # ì§„í–‰ ìƒí™© ì¶œë ¥ (1000ê°œë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰)
                if total_saved % 1000 == 0 or total_saved == len(self.df):
                    logger.info(f"  ì§„í–‰: {total_saved}/{len(self.df)} ë ˆì½”ë“œ ì €ì¥ë¨")
            
            # ì €ì¥ í™•ì¸
            with self.engine.connect() as conn:
                count_result = conn.execute(
                    text(f"SELECT COUNT(*) FROM {self.table_name}")
                ).scalar()
                
                logger.info(f"âœ… ì €ì¥ ì™„ë£Œ: ì´ {count_result}ê°œ ë ˆì½”ë“œ")
                
                # ìƒ˜í”Œ ë°ì´í„° í™•ì¸ (ì²˜ìŒ 3ê°œ)
                sample_query = f"SELECT * FROM {self.table_name} LIMIT 3"
                sample_result = conn.execute(text(sample_query)).fetchall()
                
                if sample_result:
                    logger.info("\nğŸ“‹ ì €ì¥ëœ ë°ì´í„° ìƒ˜í”Œ:")
                    for i, row in enumerate(sample_result, 1):
                        logger.info(f"  ë ˆì½”ë“œ {i}:")
                        row_dict = dict(row._mapping)
                        # ì£¼ìš” ì»¬ëŸ¼ë§Œ ì¶œë ¥ (ë„ˆë¬´ ë§ìœ¼ë©´ ì²˜ìŒ 5ê°œ)
                        for j, (k, v) in enumerate(row_dict.items()):
                            if j < 5:
                                logger.info(f"    {k}: {v}")
                        if len(row_dict) > 5:
                            logger.info(f"    ... ì™¸ {len(row_dict) - 5}ê°œ ì»¬ëŸ¼")
            
            return True
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def create_summary_stats(self):
        """ìš”ì•½ í†µê³„ ìƒì„±"""
        try:
            logger.info("ğŸ“Š ìš”ì•½ í†µê³„ ìƒì„± ì¤‘...")
            
            with self.engine.connect() as conn:
                # ì „ì²´ ìš”ì•½
                total_query = f"SELECT COUNT(*) as total FROM {self.table_name}"
                result = conn.execute(text(total_query)).scalar()
                logger.info(f"\nğŸ“ˆ ì „ì²´ ìš”ì•½:")
                logger.info(f"  ì´ ë ˆì½”ë“œìˆ˜: {result:,}")
                
                # í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì •ë³´
                schema_query = f"PRAGMA table_info({self.table_name})"
                schema_result = conn.execute(text(schema_query)).fetchall()
                logger.info(f"  ì»¬ëŸ¼ ìˆ˜: {len(schema_result)}")
                
                # ì£¼ìš” ì»¬ëŸ¼ë³„ í†µê³„ (ìˆëŠ” ê²½ìš°)
                for col_info in schema_result:
                    col_name = col_info[1]
                    
                    # ìì¬ ê´€ë ¨ ì»¬ëŸ¼ì´ë©´ ê³ ìœ ê°’ ìˆ˜ ê³„ì‚°
                    if 'ìì¬' in col_name or 'í”ŒëœíŠ¸' in col_name:
                        try:
                            distinct_query = f"SELECT COUNT(DISTINCT `{col_name}`) FROM {self.table_name}"
                            distinct_result = conn.execute(text(distinct_query)).scalar()
                            if distinct_result:
                                logger.info(f"  {col_name} ê³ ìœ ê°’: {distinct_result:,}ê°œ")
                        except:
                            pass
                    
                    # ê·¸ë£¹ ì»¬ëŸ¼ì´ë©´ ê³ ìœ ê°’ ìˆ˜ ê³„ì‚°
                    elif 'ê·¸ë£¹' in col_name:
                        try:
                            distinct_query = f"SELECT COUNT(DISTINCT `{col_name}`) FROM {self.table_name}"
                            distinct_result = conn.execute(text(distinct_query)).scalar()
                            if distinct_result:
                                logger.info(f"  {col_name} ê³ ìœ ê°’: {distinct_result:,}ê°œ")
                        except:
                            pass
            
            return True
            
        except Exception as e:
            logger.error(f"ìš”ì•½ í†µê³„ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def run(self):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        try:
            logger.info("=" * 60)
            logger.info("ZMMR0001 ìì¬ë¦¬ìŠ¤íŠ¸ ë°ì´í„° Import (SQLite)")
            logger.info("=" * 60)
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
            if not self.connect_database():
                return False
            
            # Excel íŒŒì¼ ë¶„ì„
            if not self.analyze_excel():
                return False
            
            # ë°ì´í„° ì •ë¦¬
            if not self.clean_and_prepare_data():
                return False
            
            # í…Œì´ë¸” ìƒì„±
            if not self.create_table():
                return False
            
            # ë°ì´í„° ì €ì¥
            if not self.save_to_database():
                return False
            
            # ìš”ì•½ í†µê³„
            self.create_summary_stats()
            
            logger.info("\n" + "=" * 60)
            logger.info("âœ… Import ì™„ë£Œ!")
            logger.info(f"ë°ì´í„°ë² ì´ìŠ¤: {self.db_path}")
            logger.info(f"í…Œì´ë¸”ëª…: {self.table_name}")
            logger.info(f"ì´ ë ˆì½”ë“œ: {len(self.df):,}")
            logger.info("=" * 60)
            
            return True
            
        except Exception as e:
            logger.error(f"í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False

if __name__ == "__main__":
    excel_file = "/Users/jinsyu/Downloads/ZMMR0001_ìì¬ë¦¬ìŠ¤íŠ¸.XLSX"
    db_file = "db.sqlite"  # SQLite ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼
    
    if not os.path.exists(excel_file):
        logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {excel_file}")
    else:
        importer = MaterialsDataImporter(excel_file, db_file)
        importer.run()