#!/usr/bin/env python3
"""
ZSDR0340 êµ­ë‚´ì˜ì—… ë§¤ì¶œ ë¶„ì„ë ˆí¬íŠ¸ Excel Import
Excel íŒŒì¼ì„ SQLite ë°ì´í„°ë² ì´ìŠ¤ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
"""

import os
import pandas as pd
import numpy as np
from sqlalchemy import create_engine, text
from datetime import datetime
import logging
from typing import Dict, List, Any

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SalesDataImporter:
    def __init__(self, excel_path: str, db_path: str = "db.sqlite"):
        self.excel_path = excel_path
        self.db_path = db_path
        self.engine = None
        self.table_name = 'sap_zsdr0340_sales_detail'
        self.df = None
        
    def connect_database(self):
        """SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        try:
            # SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
            self.engine = create_engine(f'sqlite:///{self.db_path}')
            logger.info(f"âœ… SQLite ì—°ê²° ì„±ê³µ: {self.db_path}")
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            with self.engine.connect() as conn:
                result = conn.execute(text("SELECT sqlite_version()")).scalar()
                logger.info(f"  SQLite ë²„ì „: {result}")
            
            return True
        except Exception as e:
            logger.error(f"âŒ SQLite ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    def analyze_excel(self):
        """Excel íŒŒì¼ êµ¬ì¡° ë¶„ì„"""
        try:
            logger.info(f"ğŸ“Š Excel íŒŒì¼ ë¶„ì„ ì¤‘: {self.excel_path}")
            
            # Excel íŒŒì¼ì˜ ëª¨ë“  ì‹œíŠ¸ í™•ì¸
            xl_file = pd.ExcelFile(self.excel_path)
            logger.info(f"ì‹œíŠ¸ ëª©ë¡: {xl_file.sheet_names}")
            
            # ì²« ë²ˆì§¸ ì‹œíŠ¸ ì½ê¸° (ë˜ëŠ” íŠ¹ì • ì‹œíŠ¸)
            self.df = pd.read_excel(self.excel_path, sheet_name=0)
            
            logger.info(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            logger.info(f"  - í–‰ ìˆ˜: {len(self.df)}")
            logger.info(f"  - ì—´ ìˆ˜: {len(self.df.columns)}")
            logger.info(f"\nğŸ“‹ ì»¬ëŸ¼ ëª©ë¡:")
            for col in self.df.columns:
                dtype = str(self.df[col].dtype)
                null_count = self.df[col].isnull().sum()
                logger.info(f"  - {col}: {dtype} (null: {null_count})")
            
            # ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
            logger.info("\nğŸ“‹ ìƒ˜í”Œ ë°ì´í„° (ì²˜ìŒ 3í–‰):")
            logger.info(self.df.head(3).to_string())
            
            return True
            
        except Exception as e:
            logger.error(f"Excel íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def clean_column_names(self):
        """ì»¬ëŸ¼ëª… ì •ë¦¬ ë° í‘œì¤€í™”"""
        try:
            # ì»¬ëŸ¼ëª… ì •ë¦¬
            new_columns = []
            column_mapping = {}
            
            for col in self.df.columns:
                # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
                clean_name = col.strip()
                # ì˜ì–´ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë§¤í•‘ (í•„ìš”ì‹œ)
                # ì—¬ê¸°ì„œëŠ” í•œê¸€ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                new_columns.append(clean_name)
                column_mapping[col] = clean_name
            
            self.df.columns = new_columns
            logger.info("âœ… ì»¬ëŸ¼ëª… ì •ë¦¬ ì™„ë£Œ")
            
            return column_mapping
            
        except Exception as e:
            logger.error(f"ì»¬ëŸ¼ëª… ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return None
    
    def infer_data_types(self):
        """ë°ì´í„° íƒ€ì… ì¶”ë¡  ë° ë³€í™˜"""
        try:
            logger.info("ğŸ” ë°ì´í„° íƒ€ì… ì¶”ë¡  ì¤‘...")
            
            for col in self.df.columns:
                # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬ - SQLiteëŠ” DATE íƒ€ì…ì´ ì—†ìœ¼ë¯€ë¡œ ë¬¸ìì—´ë¡œ ì €ì¥
                if 'ì¼' in col or 'ë‚ ì§œ' in col or 'date' in col.lower():
                    try:
                        # ë‚ ì§œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (YYYY-MM-DD í˜•ì‹)
                        self.df[col] = pd.to_datetime(self.df[col], errors='coerce').dt.strftime('%Y-%m-%d')
                        logger.info(f"  {col}: ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜")
                    except:
                        pass
                
                # ìˆ«ì ì»¬ëŸ¼ ì²˜ë¦¬
                elif self.df[col].dtype == 'object':
                    try:
                        # ì½¤ë§ˆ ì œê±° í›„ ìˆ«ì ë³€í™˜ ì‹œë„
                        temp = self.df[col].astype(str).str.replace(',', '').str.replace(' ', '')
                        if temp.str.match(r'^-?\d+\.?\d*$').all():
                            self.df[col] = pd.to_numeric(temp, errors='coerce')
                            logger.info(f"  {col}: ìˆ«ì íƒ€ì…ìœ¼ë¡œ ë³€í™˜")
                    except:
                        pass
            
            logger.info("âœ… ë°ì´í„° íƒ€ì… ì¶”ë¡  ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ë°ì´í„° íƒ€ì… ì¶”ë¡  ì‹¤íŒ¨: {e}")
            return False
    
    def create_table(self):
        """SQLite í…Œì´ë¸” ìƒì„±"""
        try:
            # ê¸°ì¡´ í…Œì´ë¸” ì‚­ì œ
            with self.engine.connect() as conn:
                conn.execute(text(f"DROP TABLE IF EXISTS {self.table_name}"))
                conn.commit()
            
            logger.info(f"ğŸ“ {self.table_name} í…Œì´ë¸” ìƒì„± ì¤‘...")
            
            # pandas to_sqlì„ ì‚¬ìš©í•˜ì—¬ í…Œì´ë¸” ìë™ ìƒì„± (SQLiteëŠ” ë™ì  íƒ€ì…)
            # ì²« ë²ˆì§¸ í–‰ë§Œ ì‚¬ìš©í•˜ì—¬ ìŠ¤í‚¤ë§ˆ ìƒì„±
            self.df.head(1).to_sql(
                self.table_name,
                self.engine,
                if_exists='replace',
                index=False
            )
            
            # í…Œì´ë¸” ë¹„ìš°ê¸° (ìŠ¤í‚¤ë§ˆë§Œ ë‚¨ê¸°ê¸°)
            with self.engine.connect() as conn:
                conn.execute(text(f"DELETE FROM {self.table_name}"))
                conn.commit()
                
                # ì¸ë±ìŠ¤ ìƒì„±
                # ì²­êµ¬ì¼ ì¸ë±ìŠ¤
                if 'ì²­êµ¬ì¼' in self.df.columns:
                    conn.execute(text(f"CREATE INDEX idx_{self.table_name}_billing_date ON {self.table_name} (ì²­êµ¬ì¼)"))
                
                # íŒë§¤ì²˜ ì¸ë±ìŠ¤
                if 'íŒë§¤ì²˜' in self.df.columns:
                    conn.execute(text(f"CREATE INDEX idx_{self.table_name}_customer ON {self.table_name} (íŒë§¤ì²˜)"))
                
                # ìì¬ ì¸ë±ìŠ¤
                if 'ìì¬' in self.df.columns:
                    conn.execute(text(f"CREATE INDEX idx_{self.table_name}_material ON {self.table_name} (ìì¬)"))
                
                conn.commit()
            
            logger.info(f"âœ… í…Œì´ë¸” ìƒì„± ì™„ë£Œ: {self.table_name}")
            return True
            
        except Exception as e:
            logger.error(f"í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def save_to_database(self):
        """ë°ì´í„°ë¥¼ SQLiteì— ì €ì¥"""
        try:
            logger.info(f"ğŸ’¾ {len(self.df)}ê°œ ë ˆì½”ë“œ ì €ì¥ ì¤‘...")
            
            # NaNì„ Noneìœ¼ë¡œ ë³€í™˜ (PostgreSQL NULL)
            df_to_save = self.df.replace({np.nan: None})
            
            # SQLiteëŠ” ë³€ìˆ˜ ì œí•œì´ ìˆìœ¼ë¯€ë¡œ ì‘ì€ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì €ì¥
            # 68ê°œ ì»¬ëŸ¼ * 14í–‰ = 952 ë³€ìˆ˜ (SQLite ì œí•œ: 999)
            chunk_size = 14
            total_saved = 0
            
            for i in range(0, len(df_to_save), chunk_size):
                chunk = df_to_save.iloc[i:i+chunk_size]
                
                chunk.to_sql(
                    self.table_name,
                    self.engine,
                    if_exists='append',
                    index=False,
                    method='multi'
                )
                
                total_saved += len(chunk)
                if total_saved % 1000 == 0 or total_saved == len(df_to_save):
                    logger.info(f"  ì§„í–‰: {total_saved}/{len(df_to_save)} ë ˆì½”ë“œ ì €ì¥ë¨")
            
            # ì €ì¥ í™•ì¸
            with self.engine.connect() as conn:
                count_result = conn.execute(
                    text(f"SELECT COUNT(*) FROM {self.table_name}")
                ).scalar()
                
                logger.info(f"âœ… ì €ì¥ ì™„ë£Œ: ì´ {count_result}ê°œ ë ˆì½”ë“œ")
                
                # ìƒ˜í”Œ ë°ì´í„° í™•ì¸
                sample_result = conn.execute(
                    text(f"SELECT * FROM {self.table_name} LIMIT 3")
                ).fetchall()
                
                if sample_result:
                    logger.info("\nğŸ“‹ ì €ì¥ëœ ë°ì´í„° ìƒ˜í”Œ:")
                    for row in sample_result:
                        logger.info(f"  {dict(row._mapping)}")
            
            return True
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def create_summary_view(self):
        """ë¶„ì„ìš© ë·° ìƒì„±"""
        try:
            logger.info("ğŸ“Š ë¶„ì„ìš© ë·° ìƒì„± ì¤‘...")
            
            # SQLiteëŠ” CREATE OR REPLACE VIEWë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ DROP í›„ ìƒì„±
            with self.engine.connect() as conn:
                try:
                    # ê¸°ì¡´ ë·° ì‚­ì œ
                    conn.execute(text("DROP VIEW IF EXISTS v_monthly_sales_summary"))
                    
                    # ì›”ë³„ ë§¤ì¶œ ì§‘ê³„ ë·° (SQLite ë²„ì „)
                    view_sql = f"""
                    CREATE VIEW v_monthly_sales_summary AS
                    SELECT 
                        substr(ì²­êµ¬ì¼, 1, 7) as month,
                        COUNT(*) as transaction_count,
                        SUM(ì²­êµ¬ê¸ˆì•¡) as total_amount
                    FROM {self.table_name}
                    WHERE ì²­êµ¬ì¼ IS NOT NULL
                    GROUP BY substr(ì²­êµ¬ì¼, 1, 7)
                    ORDER BY month DESC;
                    """
                    
                    conn.execute(text(view_sql))
                    conn.commit()
                    logger.info("âœ… ì›”ë³„ ë§¤ì¶œ ì§‘ê³„ ë·° ìƒì„± ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"ë·° ìƒì„± ì‹¤íŒ¨: {e}")
            
            return True
            
        except Exception as e:
            logger.error(f"ë·° ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def run(self):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        try:
            logger.info("=" * 60)
            logger.info("ZSDR0340 ë§¤ì¶œ ë°ì´í„° Import ì‹œì‘")
            logger.info("=" * 60)
            
            # SQLite ì—°ê²°
            if not self.connect_database():
                return False
            
            # Excel íŒŒì¼ ë¶„ì„
            if not self.analyze_excel():
                return False
            
            # ì»¬ëŸ¼ëª… ì •ë¦¬
            self.clean_column_names()
            
            # ë°ì´í„° íƒ€ì… ì¶”ë¡ 
            self.infer_data_types()
            
            # í…Œì´ë¸” ìƒì„±
            if not self.create_table():
                return False
            
            # ë°ì´í„° ì €ì¥
            if not self.save_to_database():
                return False
            
            # ë¶„ì„ ë·° ìƒì„±
            self.create_summary_view()
            
            logger.info("\n" + "=" * 60)
            logger.info("âœ… Import ì™„ë£Œ!")
            logger.info(f"í…Œì´ë¸”ëª…: {self.table_name}")
            logger.info(f"ì´ ë ˆì½”ë“œ: {len(self.df)}")
            logger.info("=" * 60)
            
            return True
            
        except Exception as e:
            logger.error(f"í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False

if __name__ == "__main__":
    excel_file = "/Users/jinsyu/Downloads/ZSDR0340_êµ­ë‚´ì˜ì—…_ë§¤ì¶œ_ë¶„ì„ë ˆí¬íŠ¸.XLSX"
    db_file = "db.sqlite"  # SQLite ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼
    
    if not os.path.exists(excel_file):
        logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {excel_file}")
    else:
        importer = SalesDataImporter(excel_file, db_file)
        importer.run()